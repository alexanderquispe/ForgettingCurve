{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ff5edb-baef-462e-a4ab-6b85ae765752",
   "metadata": {},
   "source": [
    "## 1. Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ab5075-8b38-4655-a8b7-0ec50ec0f71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2c078-722f-4476-8e37-e58c5f3d2ec7",
   "metadata": {},
   "source": [
    "## 2. Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87feae8a-2d2c-4d55-80b6-405f4ad87c39",
   "metadata": {},
   "source": [
    "Funciones\n",
    "\n",
    "1. **estimate_h_hat**: Permite estimar h_hat dados los valores de theta y x. Ecuación N. 2. \n",
    "2. **estimate_p_hat**: Permite estimar p_hat dados los valores de delta y h_hat. Ecuación N. 4.\n",
    "3. **hh_loss_function**: Permite estimar el costo de la función tomando en cuenta el valor de p, p_hat, h_hat, delta y lambda. Ecuación N. 9. \n",
    "4. **gradient_partial**: Permite estimar el gradiente de la función de costo. Ecuación N. 10.\n",
    "5. **adagrad_update**: Permite actualizar el valor de theta con cada iteración utilizando el algoritmo SGD adagrad. Ecuación N. 11.\n",
    "6. **half_life_regression**: Modelo HLR que integra todas las funciones anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb957ed1-d066-4a28-8fa4-c0c19ac0384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_h_hat( theta, x ):\n",
    "    \n",
    "    '''\n",
    "    Objetivo:\n",
    "        - Estimar hat{h} a través de la ecuación N. 2:\n",
    "          \\hat{h} = 2^{Theta \\cdot x}\n",
    "          \n",
    "    Input:\n",
    "        - theta : valor de los coeficientes de x\n",
    "        - x     : variables predictoras\n",
    "        \n",
    "    Output:\n",
    "        - estimated_half_life: hat{h}\n",
    "    '''\n",
    "    estimated_h = 2 ** np.dot( theta.T, x )\n",
    "    \n",
    "    return estimated_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b177dc80-36db-4e4d-86b4-cd0c92e830cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_p_hat( delta, estimated_h ):\n",
    "    \n",
    "    '''\n",
    "    Objetivo:\n",
    "        - Estimar  hat{p} a través de la ecuación N. 4:\n",
    "          \\hat{p}_{\\Theta} = 2^{-\\Delta/\\hat{h}_{\\Theta}}\n",
    "   \n",
    "   Input:\n",
    "       - delta       : tiempo transcurrido desde \n",
    "                       la última práctica\n",
    "       - estimated_h : valor estimado de la capacidad\n",
    "                       de memoria o half_life ( hat{h} ).\n",
    "   \n",
    "   Output:\n",
    "       - predicted_p : valor estimado de la probabilidad\n",
    "                       de recordar( hat{p} )\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    predicted_p = 2 ** ( - delta / estimated_h )\n",
    "    \n",
    "    return predicted_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0f5f10c-c918-42d0-a72b-b9796339ab0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hh_loss_function( p, predicted_p, estimated_h, delta, theta, lambda_param = 0.1, alpha_param = 0.01 ):\n",
    "    \n",
    "    '''\n",
    "    Objetivo: \n",
    "        - Calcular el valor de pérdida del modelo Half Life Regression\n",
    "          Ecuación N. 9.\n",
    "    \n",
    "    Input:\n",
    "        - p            : probabilidad de recordar real\n",
    "        - predicted_p  : probabilidad de recordar predicha\n",
    "                         mediante la función predict_recall_probability\n",
    "        - estimated_h  : capacidad de memoria estimada\n",
    "        - delta        : tiempo transcurrido desde la última práctica\n",
    "        - theta        : valor de los coeficientes de x\n",
    "        - lambda_param : parámetro lambda de importancia relativa de la\n",
    "                         semivida en la función de pérdida\n",
    "        - alpha_param  : parámetro de regularización L2\n",
    "        \n",
    "    Output:\n",
    "        - Valor de pérdida de la función Half Life Regression\n",
    "    '''\n",
    "    \n",
    "    loss_p              = np.square( p - predicted_p )\n",
    "    loss_h              = np.square( ( -delta / np.log2( p ) ) - estimated_h )\n",
    "    regularization_term = lambda_param * np.sum( np.square( theta ) )\n",
    "    \n",
    "    loss = loss_p + alpha_param * loss_h + regularization_term  \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "123689ed-38e3-4547-a3c3-9d57ac90fa4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_partial( p, predicted_p, estimated_h, delta, x, theta, lambda_param = 0.1, alpha_param = 0.01 ):\n",
    "    \n",
    "    '''\n",
    "    Calcula la derivada parcial de la función de pérdida con respecto a cada peso theta_k.\n",
    "\n",
    "    Input:\n",
    "    - p            : probabilidad de recordar real\n",
    "    - predicted_p  : probabilidad de recordar predicha\n",
    "    - estimated_h  : capacidad de memoria estimada\n",
    "    - delta        : tiempo transcurrido desde la última práctica\n",
    "    - x            : vector de características\n",
    "    - theta        : vector de pesos\n",
    "    - lambda_param : parámetro lambda de importancia relativa de la semivida en la función de pérdida\n",
    "    - alpha_param  : parámetro de regularización L2\n",
    "\n",
    "    Output:\n",
    "    - gradient : vector de derivadas parciales con respecto a cada theta_k\n",
    "    '''\n",
    "    \n",
    "    term1 = 2 * ( predicted_p - p ) * np.log( 2 ) * predicted_p * ( 2**( -delta / estimated_h ) ) * x\n",
    "    term2 = 2 * alpha_param * ( estimated_h + delta / np.log2( p ) ) * np.log( 2 ) * estimated_h * x\n",
    "    term3 = 2 * lambda_param * theta\n",
    "\n",
    "    gradient = term1 + term2 + term3\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca6489bb-ab4c-40e6-b829-d0c87e44e604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adagrad_update( theta, gradient, learning_rate, csg ):\n",
    "    \n",
    "    '''\n",
    "    Actualiza los pesos utilizando el algoritmo AdaGrad.\n",
    "\n",
    "    Input:\n",
    "    - theta         : vector de pesos\n",
    "    - gradient      : vector de derivadas parciales con respecto a cada theta_k\n",
    "    - learning_rate : tasa de aprendizaje\n",
    "    - csg           : acumulación de los cuadrados de los gradientes anteriores\n",
    "\n",
    "    Output:\n",
    "    - theta_updated : vector de pesos actualizado\n",
    "    '''\n",
    "    \n",
    "    csg_updated = csg + gradient**2\n",
    "    theta_updated = theta - ( learning_rate / np.sqrt( csg_updated + 1e-8 ) ) * gradient\n",
    "\n",
    "    return theta_updated, csg_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c2c3bf2c-cd5c-4e9c-bf11-61c301417dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def half_life_regression( X, y, delta, learning_rate=0.01, lambda_param=0.1, alpha_param=0.01, num_iterations = 1000 ):\n",
    "    '''\n",
    "    Implementa el modelo de Half-Life Regression.\n",
    "\n",
    "    Input:\n",
    "    - X               : Matriz de características (dimensiones: m x n)\n",
    "    - y               : Vector de etiquetas (dimensiones: m x 1)\n",
    "    - theta_init      : Vector de pesos iniciales (dimensiones: n x 1)\n",
    "    - learning_rate   : Tasa de aprendizaje para el algoritmo de optimización (por defecto: 0.01)\n",
    "    - lambda_param    : Parámetro lambda de importancia relativa de la semivida en la función de pérdida (por defecto: 0.1)\n",
    "    - alpha_param     : Parámetro de regularización L2 (por defecto: 0.01)\n",
    "    - num_iterations  : Número de iteraciones para el algoritmo de optimización (por defecto: 1000)\n",
    "\n",
    "    Output:\n",
    "    - theta_optimized : Vector de pesos optimizados\n",
    "    '''\n",
    "\n",
    "    # Inicialización de variables\n",
    "    \n",
    "    m     = X.shape[ 1 ]   # n_rows\n",
    "    n     = X.shape[ 0 ]   # n_columns\n",
    "    theta = np.zeros( ( n, 1 ) ) # weights: matriz vacía. Coeficientes. \n",
    "    \n",
    "    # theta = np.random.rand(X.shape[1])\n",
    "    csg = np.zeros_like(theta)\n",
    "\n",
    "    cost_list = []\n",
    "    # Iteraciones de optimización\n",
    "    for iteration in range(num_iterations):\n",
    "        # Predicción de la semivida y probabilidad de recordar\n",
    "        estimated_h = estimate_h_hat(theta, X)       \n",
    "        predicted_p = estimate_p_hat(delta, estimated_h)\n",
    "\n",
    "        # Cálculo de la pérdida y el gradiente\n",
    "        loss     = hh_loss_function(y, predicted_p, estimated_h, delta, theta, lambda_param, alpha_param)\n",
    "        gradient = gradient_partial(y, predicted_p, estimated_h, delta, X, theta, lambda_param, alpha_param)\n",
    "\n",
    "        # Actualización de pesos con AdaGrad\n",
    "        theta, csg = adagrad_update(theta, gradient, learning_rate, csg)\n",
    "\n",
    "        # Mostrar la pérdida en cada 100 iteraciones\n",
    "        if iteration % 100 == 0:\n",
    "            print(f\"Iteration {iteration}, Loss: {loss}\")\n",
    "            \n",
    "        cost_list.append( loss )\n",
    "\n",
    "    return theta, cost_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5abfd70-cad9-43c1-8c4b-8a48fb609fb8",
   "metadata": {},
   "source": [
    "## Primer intento con datos de Duolingo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08097665-498a-4ae0-bcf7-0f983e8f181c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data      = pd.read_csv( 'subset_1000.csv' )\n",
    "pred_vars = [ 'right', 'wrong', 'bias', 't' ]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( data[ pred_vars ], \n",
    "                                                     data[ 'p' ], \n",
    "                                                     test_size    = 0.30,\n",
    "                                                     random_state = 2023 )\n",
    "\n",
    "t_train = X_train[ 't' ].values\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values\n",
    "X_test = X_test.values\n",
    "Y_test = Y_test.values\n",
    "\n",
    "X_train = X_train.T\n",
    "Y_train = Y_train.reshape( 1, X_train.shape[ 1 ] )\n",
    "t_train = t_train.reshape( 1, X_train.shape[ 1 ] )\n",
    "\n",
    "X_test = X_test.T\n",
    "Y_test = Y_test.reshape( 1, X_test.shape[ 1 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f826f15-d6b1-4193-8166-c42f8d4d45aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: [[2.69441249e+09 7.37540538e+01 1.70376242e+02 9.46436415e+08\n",
      "  2.66597506e+01 7.46280790e+01 1.07364127e+10 1.70844490e+07\n",
      "  2.53931835e+09 6.85275405e+02 4.03974766e+06 5.20247570e+10\n",
      "  1.48721276e+07 3.60023932e+06 1.69106439e+08 1.43552434e+03\n",
      "  7.44384112e+06 1.22296864e+03 1.06474829e+08 3.09851513e+05\n",
      "  4.29282051e+06 1.21306116e+08 2.85250596e+01 4.57751992e+08\n",
      "  4.38341591e+08 3.67764730e+03 8.13473722e+01 1.89423892e+02\n",
      "  6.57388621e+07 4.10413328e+01 1.08991475e+02 7.09760674e+06\n",
      "  2.43009372e+01 1.37983476e+06 3.27345208e+01 1.34438311e+01\n",
      "  1.09635148e+00 2.03892071e-01 8.29536859e+00 4.00346582e+09\n",
      "  2.11423184e+03 1.01702478e+06 2.59113784e+02 8.12606442e-01\n",
      "  2.44621601e+02 6.94611536e+01 3.63105988e+01 3.38637296e+07\n",
      "  5.82654330e+05 6.50237965e+06 4.93103944e+00 1.45411165e+00\n",
      "  4.42341364e+06 6.78389531e-01 3.16918504e+07 1.90915268e+07\n",
      "  5.58505184e-02 8.43019885e+02 2.26710676e+02 6.69471939e+01\n",
      "  5.40132627e+08 1.20449317e+10 1.56118132e+02 1.94343474e+02\n",
      "  5.77791123e+06 4.41648031e+06 6.89842838e+00 5.92765210e-02\n",
      "  2.80713534e+03 3.36356861e+09 3.25371235e+03 1.09362361e+00\n",
      "  4.87856978e+06 4.78498182e+00 6.99603127e-02 8.01960846e+08\n",
      "  1.25698839e+08 2.05206822e+08 1.92227359e+02 2.10584189e+06\n",
      "  3.20542829e+04 1.56183347e+03 1.62017073e+04 3.46171937e+06\n",
      "  3.63477794e+02 2.95231955e+08 1.42705363e+09 3.06351229e+04\n",
      "  3.15836817e+01 3.80260365e+02 3.46651952e-01 1.31686354e+07\n",
      "  7.59487699e+01 8.80613116e+07 2.31183353e+01 6.37569090e+00\n",
      "  1.96039046e+01 1.07680255e+03 3.15836817e+01 5.12985327e+07\n",
      "  2.51111110e+01 4.11390688e+02 1.81065351e+07 1.09811476e+00\n",
      "  9.25988364e+02 1.75480770e+07 5.94557963e+03 6.37569090e+00\n",
      "  2.64795235e+10 3.61565881e+06 7.81756634e+01 5.53842590e+07\n",
      "  2.48575092e+01 2.56221758e+01 1.43598729e+07 8.90788265e+00\n",
      "  5.28060408e+00 6.49843641e+08 1.58981131e+09 1.57155164e+07\n",
      "  7.42284031e-01 5.90496448e-01 8.13473722e+01 1.10975076e+11\n",
      "  1.18075607e+03 1.16778689e+08 2.75705306e+02 3.30555892e+09\n",
      "  6.35251861e+02 7.81756634e+01 8.04347342e+01 4.78762968e+03\n",
      "  4.87123021e+07 1.08659735e-01 1.36982163e+07 1.59067466e-01\n",
      "  4.97983547e+06 9.71491951e+01 1.88854526e+08 1.45672991e+07\n",
      "  4.76301965e+07 5.22852993e+09 2.87966807e+01 9.71491951e+01\n",
      "  3.42020292e+01 1.48603549e+02 1.18689483e+04 5.47034947e-01\n",
      "  1.18639225e+08 6.31537141e+06 5.84259924e+09 2.70868930e+07\n",
      "  4.22735646e+07 1.09772626e+00 1.42064811e+08 1.27171846e+02\n",
      "  4.99925104e+08 6.25391851e+10 1.05672177e+09 7.44175934e+00\n",
      "  4.95876667e+07 8.16490366e-02 5.30989629e+05 4.22016816e+07\n",
      "  3.41267140e+07 4.89169009e+06 7.43921355e-02 2.10221304e+07\n",
      "  1.08208362e+00 4.60952244e+09 7.91228714e+00 1.09262469e+00\n",
      "  4.14255463e+08 1.37311572e+09 3.40488073e+07 2.46767261e+08\n",
      "  1.71039139e+02 3.13120444e+02 3.23074025e+02 9.73187200e+08\n",
      "  2.43013645e+00 7.28666836e+08 1.86895300e+07 6.39319686e+07\n",
      "  3.89674043e+06 4.60254070e+06 1.79529309e+07 1.72606693e+08\n",
      "  7.04314922e+10 2.82845937e-02 1.48219131e-01 1.04208904e+09\n",
      "  1.75410640e+07 1.11136947e+10 3.03814993e+08 4.73923205e+08\n",
      "  2.63213399e+02 1.84605384e+10 1.25297728e+01 5.02864358e+01\n",
      "  6.62914897e+08 1.61743776e+01 7.02548708e-03 1.96471172e+02\n",
      "  1.28404758e-07 1.35592219e+03 1.51087816e+02 2.19146811e+01\n",
      "  1.73871321e+07 1.55467770e+08 3.18864594e+08 2.48575092e+01\n",
      "  2.74278376e+08 3.12463613e+08 4.85078584e+08 3.39443426e-01\n",
      "  1.02214351e+02 3.12991897e+01 4.33481148e+01 5.34380588e+06\n",
      "  1.63790698e+01 7.57503849e-02 1.12425454e-01 4.00484567e+06\n",
      "  2.97168697e+02 1.11854887e+06 3.44889418e-01 1.17081522e+02\n",
      "  4.12420407e+02 1.97932921e+07 7.44175934e+00 2.98043965e+02\n",
      "  4.83393825e+08 3.71324880e+09 9.52675708e+03 9.92851766e+08\n",
      "  1.70314334e+07 3.95288495e+07 8.02206166e-06 4.86462887e+09\n",
      "  1.65119398e+02 5.89061977e+05 2.67910298e+06 4.76770319e+06\n",
      "  1.09693351e+00 8.21924785e+07 3.48124198e+07 3.29934889e+11\n",
      "  5.04002344e+06 2.51815566e+02 9.73002774e-01 1.63214126e+03\n",
      "  4.58143624e+05 3.50885119e-01 5.23540280e+06 2.61340674e+06\n",
      "  5.91283199e+02 2.81633968e+02 1.65969349e+08 1.84967823e+01\n",
      "  2.12079336e+01 3.21565271e+01 4.38380280e+00 4.08044104e+07\n",
      "  7.07355092e+01 4.52700395e+03 9.81519296e+01 3.73843490e+06\n",
      "  2.93437842e+01 4.27580949e+08 3.76161389e+02 3.47980422e+01\n",
      "  1.18182076e+02 4.19788386e+07 4.73419491e+06 1.56709681e-01\n",
      "  5.85549041e+06 3.48750789e-01 3.22342577e-01 2.21908953e+06\n",
      "  8.17409040e-02 1.69823924e+09 2.41514527e+08 4.81508816e+01\n",
      "  9.88120520e+08 7.90839836e+03 4.89982135e-02 2.98043965e+02\n",
      "  1.04924624e+00 5.04230177e+06 1.58815011e-02 2.40169677e+08\n",
      "  5.85594028e+03 2.39063866e+08 8.08267583e+06 5.25524007e+08\n",
      "  2.51111110e+01 1.41077790e+07 6.01556024e+06 2.88927194e+06\n",
      "  6.00759349e+01 8.10149857e+08 4.32289535e+07 1.09801762e+00\n",
      "  4.69003065e+06 1.11496822e+08 6.24822427e+00 3.36444382e-01\n",
      "  9.55882685e-03 3.47175807e-01 1.67218824e+08 4.18538559e+08\n",
      "  2.28430189e+07 4.54340992e+06 5.82716427e+06 4.80900367e+06\n",
      "  1.75668953e+06 5.04458060e+06 2.35459574e+08 2.35648796e+08\n",
      "  2.41044264e+01 1.34552012e+10 3.25072460e+08 1.06439232e+08\n",
      "  1.77238389e-01 6.61195041e+01 5.18363913e+06 1.58132175e+07\n",
      "  4.07169408e+01 8.16965930e+08 2.43541669e+01 7.90779875e+06\n",
      "  6.74194202e+02 2.88847958e+04 1.74779188e+08 1.39357387e+00\n",
      "  5.96833271e+01 1.17692257e+08 2.34487410e+08 1.47985699e+02\n",
      "  2.19856198e+10 1.12427807e+09 5.03222600e+08 2.54236721e+02\n",
      "  5.92768282e+09 2.21161341e+06 5.00273240e+06 1.91836201e+03\n",
      "  7.14224868e+07 1.09275353e+00 5.17358805e+01 2.07224762e-01\n",
      "  5.14512430e+03 5.25568776e+05 4.60616627e+01 3.46487723e-01\n",
      "  3.04839857e+11 4.18002016e+07 4.64066481e+01 1.55548214e+07\n",
      "  1.04276452e+02 2.09749253e+01 3.33176628e+01 2.56403752e+05\n",
      "  8.73954898e+00 4.36911928e+10 3.76119116e+03 4.00720183e+01\n",
      "  3.70280393e+02 2.30641983e+08 8.21316205e+06 1.18582863e+08\n",
      "  2.03487193e+08 3.84074794e+02 9.42941774e+10 2.64547714e+04\n",
      "  2.32735618e+08 1.88517365e+03 1.54323856e-01 4.36828035e+01\n",
      "  4.58745421e+07 1.05530774e+00 1.74376929e+09 5.05872089e+06\n",
      "  1.55441655e+10 3.01557907e+02 8.97472344e+10 3.50979793e+01\n",
      "  2.09749253e+01 1.20398628e+02 4.30230433e+07 2.23968332e+03\n",
      "  3.53992035e+01 1.56980653e-01 5.14973342e+06 4.36680609e+07\n",
      "  3.63785177e+09 4.36828035e+01 1.77406182e-01 1.14753770e+01\n",
      "  6.89297364e+05 1.77336851e+07 3.27327339e+10 3.08873330e+10\n",
      "  4.34958993e+07 5.56046444e+02 2.05687088e+00 2.93437842e+01\n",
      "  1.69530945e+08 2.93515688e+00 2.63984263e+01 1.65687377e+07\n",
      "  4.18074185e+07 1.43708373e+10 4.40635677e+06 1.58828724e+00\n",
      "  1.30048722e+02 7.21091002e+02 4.41569121e+07 1.37268913e-01\n",
      "  1.63790698e+01 1.91137883e+08 1.05315226e+02 1.89351971e+00\n",
      "  3.45268242e+07 3.92563832e+06 8.04347342e+01 4.11125325e+03\n",
      "  1.04276452e+02 2.33835246e+08 3.97186344e+00 1.40171323e-01\n",
      "  9.98066211e+00 2.47008006e+02 2.59572029e+06 3.72335779e+01\n",
      "  4.45312832e+06 2.38472741e+08 1.11342085e+01 1.50979900e+07\n",
      "  1.06301601e+00 1.75715460e+02 3.60055133e+01 5.23051850e+02\n",
      "  1.95706799e+07 9.73003250e-01 8.23995323e+02 5.81257665e+01\n",
      "  2.09218527e+09 3.04636225e+08 1.68395272e+02 4.70828350e+00\n",
      "  4.22686166e+07 1.04332079e+07 1.17345652e+06 1.60505615e+07\n",
      "  5.33804997e+09 1.97542610e+07 2.48012961e+08 2.71862606e+01\n",
      "  5.54779978e+06 1.00755754e+10 1.86641019e+02 4.71004802e+01\n",
      "  1.93665069e+08 3.20343967e+02 6.36707003e-01 3.93357547e+08\n",
      "  9.28105998e+06 9.53987305e+02 1.82958560e+06 1.07981884e+01\n",
      "  1.89815110e+09 9.71491951e+01 5.17358805e+01 3.26732122e+02\n",
      "  3.39387610e-01 5.24683254e+01 2.27475254e+02 4.13670118e+01\n",
      "  8.34409615e+07 7.14360005e+08 1.19649362e+08 6.78152148e+02\n",
      "  3.46274992e+02 1.26953555e+03 2.53659998e+01 3.24448804e+01\n",
      "  1.21731592e+01 1.57688544e+01 2.49712179e+08 3.10196915e+08\n",
      "  2.71509159e+02 3.48029572e-01 8.41956960e+05 1.18734284e+02\n",
      "  1.34442627e+10 1.09011562e+00 4.63786417e+03 7.30399596e+00\n",
      "  3.90440771e+08 7.33272078e+03 4.63368396e+09 3.23616157e+10\n",
      "  2.74514462e+01 6.09933847e+02 3.85069761e+02 3.24902444e+10\n",
      "  7.28468034e+06 5.24115413e+09 5.17371638e-02 6.32631332e+01\n",
      "  1.63903150e+08 4.72878718e+06 1.05430198e+09 4.14384934e+03\n",
      "  1.09655549e+01 3.25815667e+02 5.54567511e+03 2.10824407e+08\n",
      "  6.34520608e+08 2.33629274e+01 1.27746380e+08 3.40244812e+05\n",
      "  5.15894375e+00 1.20454319e+08 3.57017149e+01 4.59622971e+06\n",
      "  4.79524177e-01 1.22809754e+10 2.21394670e+02 3.04534362e+01\n",
      "  2.36088067e+01 9.17261825e+01 5.80171724e+06 1.88726243e+02\n",
      "  8.59877876e+01 1.09352690e+00 4.60616627e+01 4.47564062e+06\n",
      "  1.44915760e+02 4.57721415e+06 6.90200774e+08 2.16918068e+03\n",
      "  6.20582807e+01 9.27006009e+01 7.81756634e+01 9.16784920e+09\n",
      "  1.61394014e+01 4.19372419e+04 1.03344277e+00 8.62451666e-01\n",
      "  3.21565271e+01 9.12409039e+01 4.32082132e+05 1.91391474e+00\n",
      "  4.64366771e+06 1.09472034e+00 3.22162718e+02 1.99729232e+07\n",
      "  5.77395941e+01 1.87156326e+01 1.05315226e+02 1.68756544e+02\n",
      "  7.07531030e+02 4.95694360e+01 1.28915349e+01 4.90492742e-02\n",
      "  1.07298330e+09 1.21234600e+03 1.69458286e+08 2.94550616e+02\n",
      "  9.65289171e+06 1.58576391e+11 2.85250596e+01 1.30228386e+03\n",
      "  1.23580401e+08 4.71004802e+01 4.79454122e+08 2.24183070e-02\n",
      "  1.90235295e+07 3.45298733e-01 3.96296905e+03 5.35812432e+06\n",
      "  1.35218825e+03 7.67707607e+07 9.66497584e+01 1.80629431e+01\n",
      "  4.93471534e+07 2.32856570e+09 1.84925260e+04 5.02864358e+01\n",
      "  6.41341610e+06 1.09808238e+00 3.22795877e-01 7.03233048e+00\n",
      "  7.74233722e+03 1.31228901e-01 4.91066338e+02 1.29481717e+04\n",
      "  7.81756757e+07 1.96039046e+01 4.00720183e+01 4.72613963e+06\n",
      "  1.08738683e-01 3.89543239e+01 3.03843293e+08 4.12420407e+02\n",
      "  2.72345814e+02 5.52022883e+06 1.22958940e+03 1.67339349e+03\n",
      "  4.84534353e+06 1.13810752e+02 3.08095187e+08 1.74218374e+01\n",
      "  7.33389696e+07 2.18909487e+09 5.36858960e+07 2.52549273e+09\n",
      "  1.24976197e+05 2.38559730e+01 2.79856787e+01 1.03038113e+01\n",
      "  3.36111645e+01 5.18236854e+06 4.22872721e+06 1.17631156e+02\n",
      "  6.80434544e+07 1.34101730e+03 3.80325474e+07 3.85496300e+07\n",
      "  7.04834481e+02 1.53684796e+01 1.79808885e+07 1.05846438e+04\n",
      "  8.57714779e+09 8.82345016e+06 1.41810937e+08 1.63818057e+02\n",
      "  1.11713367e+01 1.07203069e+00 5.36799406e+06 5.47870301e+07\n",
      "  4.31427368e+09 4.38380280e+00 4.00720183e+01 2.98020325e+08\n",
      "  1.09655549e+01 6.32631332e+01 7.89306833e+07 5.05791263e+02\n",
      "  3.96204868e-01 2.69722233e+10 1.13952621e+08 3.03480801e+08\n",
      "  2.51662957e+00 1.10776622e+02 3.24073652e+09 7.95770351e+07\n",
      "  3.53017530e-03 8.25900180e+09 6.42861186e-03 6.03518613e+05\n",
      "  7.07355092e+01 3.57017149e+01 7.67212093e+09 4.36828035e+01\n",
      "  6.92839829e+08 4.71004802e+01 3.45483039e-01 7.44175934e+00\n",
      "  1.59709724e+01 3.48029572e-01 3.36528433e+09 1.48545232e+07\n",
      "  4.01690821e+07 1.50184496e+07 3.77035597e+00 8.77242144e+02\n",
      "  4.00720183e+01 1.87536324e+07 8.73954898e+00 9.07569124e+01\n",
      "  3.21565271e+01 2.96000484e+08 1.71039139e+02 5.82093605e+07\n",
      "  6.03562679e+07 5.07620990e+03 3.88226323e+08 4.68916450e+08\n",
      "  4.41786654e+06 1.48865155e+09 1.27859047e+03 1.09876261e+00\n",
      "  2.13027960e+00 2.08441446e-01 6.16592373e+01 1.49866101e+08]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (700,700) (4,700) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m theta_optimized, cost_list \u001b[38;5;241m=\u001b[39m half_life_regression(X_train, Y_train, t_train)\n",
      "Cell \u001b[1;32mIn[88], line 36\u001b[0m, in \u001b[0;36mhalf_life_regression\u001b[1;34m(X, y, delta, learning_rate, lambda_param, alpha_param, num_iterations)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Cálculo de la pérdida y el gradiente\u001b[39;00m\n\u001b[0;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m hh_loss_function(y, predicted_p, estimated_h, delta, theta, lambda_param, alpha_param)\n\u001b[1;32m---> 36\u001b[0m gradient \u001b[38;5;241m=\u001b[39m gradient_partial(y, predicted_p, estimated_h, delta, X, theta, lambda_param, alpha_param)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Actualización de pesos con AdaGrad\u001b[39;00m\n\u001b[0;32m     39\u001b[0m theta, csg \u001b[38;5;241m=\u001b[39m adagrad_update(theta, gradient, learning_rate, csg)\n",
      "Cell \u001b[1;32mIn[86], line 20\u001b[0m, in \u001b[0;36mgradient_partial\u001b[1;34m(p, predicted_p, estimated_h, delta, x, theta, lambda_param, alpha_param)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient_partial\u001b[39m( p, predicted_p, estimated_h, delta, x, theta, lambda_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, alpha_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m ):\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Calcula la derivada parcial de la función de pérdida con respecto a cada peso theta_k.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    - gradient : vector de derivadas parciales con respecto a cada theta_k\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     term1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m ( predicted_p \u001b[38;5;241m-\u001b[39m p ) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog( \u001b[38;5;241m2\u001b[39m ) \u001b[38;5;241m*\u001b[39m predicted_p \u001b[38;5;241m*\u001b[39m ( \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m( \u001b[38;5;241m-\u001b[39mdelta \u001b[38;5;241m/\u001b[39m estimated_h ) ) \u001b[38;5;241m*\u001b[39m x\n\u001b[0;32m     21\u001b[0m     term2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m alpha_param \u001b[38;5;241m*\u001b[39m ( estimated_h \u001b[38;5;241m+\u001b[39m delta \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2( p ) ) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog( \u001b[38;5;241m2\u001b[39m ) \u001b[38;5;241m*\u001b[39m estimated_h \u001b[38;5;241m*\u001b[39m x\n\u001b[0;32m     22\u001b[0m     term3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m lambda_param \u001b[38;5;241m*\u001b[39m theta\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (700,700) (4,700) "
     ]
    }
   ],
   "source": [
    "theta_optimized, cost_list = half_life_regression(X_train, Y_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76004cb-7ae7-45e4-adae-a4304b948a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae801a-a27d-41d7-99b7-fd48c1b75478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd74daa-120c-42ab-b495-116846959a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7662bbd-6494-4f44-be17-3ab0e42ff362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
